import httpx
from fastapi import HTTPException
import requests
import librosa
import numpy as np
import os
import yt_dlp
import re
from .lyrics import obter_e_salvar_letras
from .images import images_generator
from moviepy import ImageClip, concatenate_videoclips, AudioFileClip, CompositeVideoClip, ImageSequenceClip


def pipeline(title, artist, album, preview_url, duration):
    print(f"\nüéµ M√∫sica Escolhida:")
    print(f"   M√∫sica: {title}")
    print(f"   Artista: {artist}")
    print(f"   √Ålbum: {album}")
    print(f"   Preview URL: {preview_url}")

    # An√°lise Librosa
    print("\n   üî¨ Analisando preview t√©cnico...")
    features, y, sr = audio_analysis(preview_url)
    
    if features:
        # Exibe features
        print("\n   üìä An√°lise T√©cnica:")
        print(f"      ‚Ä¢ üéµ BPM Level (0-10): {features['bpm']}")
        print(f"      ‚Ä¢ ‚ö° Energia Level (0-10): {features['energy']}")
        print(f"      ‚Ä¢ üï∫ Dan√ßabilidade Level (0-10): {features['danceability']}")

        # Obter Letra
        print("\n   üìù Buscando a letra...")
        lyrics = obter_e_salvar_letras(artist, title)
        # print(f"\n   üìù Letra: {lyrics}")

        print("\n   üé® Gerando imagens...")
        images = images_generator(lyrics, interpret_features(features))
        
        print("\n   üöÄ Baixando o arquivo MP3...")
        audio_info = yt_download(title, artist, album, target_duration=duration)
        if audio_info:
            print("Audio info:", audio_info)
            # Gerar v√≠deo sincronizado
            try:
                audio_path = audio_info['path']
 
                audio = AudioFileClip(audio_path)
                print("Dura√ß√£o do √°udio:", audio.duration)
                total_duration = audio.duration

            except KeyError:
                print(f"Erro ao carregar o √°udio: {audio_path} pode estar corrompido ou inv√°lido.")

            # Calcular a dura√ß√£o de cada verso (assumindo 4 imagens por par√°grafo)
            verse_duration = total_duration / len(images)

            # Criar colagem para cada conjunto de imagens e sincronizar com a m√∫sica
            collages = [create_collage(image_group, verse_duration) for image_group in images]
            sync_with_audio(collages, audio_path)

            return {
                "title": title,
                "artist": artist,
                "album": album,
                "bpm": features['bpm'],
                "energy": features['energy'],
                "danceability": features['danceability'],
                "images": images,
                "audio_path": audio_path
            }

    return {"error": "Falha ao analisar a m√∫sica."}


def audio_analysis(preview_url):
    try:
        # Baixa o preview
        audio_data = requests.get(preview_url).content
        with open("temp_preview.mp3", 'wb') as f:
            f.write(audio_data)

        # Processamento com Librosa
        y, sr = librosa.load("temp_preview.mp3", duration=30)

        # Extra√ß√£o de features (corrigido o warning do BPM)
        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
        features = {
            "bpm": np.clip(int(np.mean(tempo)) / (200 - 60) * 10, 0, 10),
            "energy": np.clip((float(np.mean(librosa.feature.rms(y=y))) - 0.01) / (0.3 - 0.01) * 10, 0, 10),
            "danceability": np.clip((float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))) - 1000) / (5000 - 1000) * 10, 0, 10),
        }
        return features, y, sr

    except Exception as e:
        print(f"‚ö†Ô∏è Erro na an√°lise: {str(e)}")
        return None, None, None
    

def interpret_features(features):
    bpm_levels = [
    "muito lenta", "lenta", "suave", "moderada", "fluida", "agitada",
    "r√°pida", "intensa", "acelerada", "extrema"
]

    energy_levels = [
        "serena e tranquila", "calma e suave", "relaxante", "moderada",
        "animada", "vibrante", "cheia de vida", "intensa", "fren√©tica", "explosiva"
    ]

    danceability_levels = [
        "totalmente est√°tica", "muito dif√≠cil de dan√ßar", "pouco dan√ßante", "suave",
        "agrad√°vel", "envolvente", "cativante", "contagiante", "irresist√≠vel", "explosiva"
    ]

    return bpm_levels[min(int(features["bpm"]),9)], energy_levels[min(int(features["energy"]),9)], danceability_levels[min(int(features["danceability"]),9)]

import re
import yt_dlp
import platform

def yt_download(title, artist, album, target_duration, tolerance=15):

    # Pr√©-processamento da query
    query = f"{title} {artist} {album}".strip()
    safe_filename = re.sub(r'[\\/*?:"<>|]', "", title)[:50].strip()

    is_win = paltform.system() == "Windows"
    base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    ffmpeg_path = os.path.join(base_path, "ffmpeg.exe") if is_win else "ffmpeg"
    ydl_opts = {
        'ffmpeg_location': ffmpeg_path,
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'outtmpl': f"{safe_filename}.%(ext)s",
        'quiet': False,  # Mostra logs para debug
        'match_filter': lambda info: (
            None if abs(info['duration'] - target_duration) <= tolerance
            else f"Dura√ß√£o {info['duration']}s fora do limite"
        ),
        'socket_timeout': 30,
        'retries': 3,
        'cookiesfrombrowser': 'chrome',
    }

    try:
        print(f"\nüîç Buscando: '{query}' (Dura√ß√£o alvo: {target_duration}s ¬±{tolerance}s)")

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # Buscar v√≠deos
            info = ydl.extract_info(f"ytsearch5:{query}", download=False)

            if not info.get('entries'):
                print("‚ùå Nenhum resultado encontrado")
                return None

            # Filtrar v√≠deos por dura√ß√£o
            videos_validos = [
                e for e in info['entries']
                if abs(e['duration'] - target_duration) <= tolerance
            ]

            if not videos_validos:
                print("‚ö†Ô∏è V√≠deos encontrados, mas fora da toler√¢ncia:")
                for vid in info['entries'][:3]:
                    print(f" - {vid['title']} ({vid['duration']}s)")
                return None

            # Melhor match
            video = min(videos_validos, key=lambda x: abs(x['duration'] - target_duration))
            print(f"‚úÖ V√≠deo adequado encontrado: {video['title']} ({video['duration']}s)")

            # Download do √°udio diretamente
            ydl.download([video['webpage_url']])

            return {
                'path': f"{safe_filename}.mp3",
                'duration': video['duration'],
                'title': video['title'],
                'url': video['webpage_url']
            }

    except Exception as e:
        print(f"‚ö†Ô∏è Erro cr√≠tico: {str(e)}")
        return None

    
# def create_collage(image_group, verse_duration):
#     print(f"üñºÔ∏è Criando colagem para {len(image_group)} imagens")
#     print(image_group)
#     image_clips = [ImageSequenceClip([img], durations=[verse_duration]) for img in image_group]
#     # No lugar de tentar criar um ImageSequenceClip com outros clips, apenas concatenar
#     return concatenate_videoclips(image_clips, method="compose")
def create_collage(image_group, verse_duration):
    print(f"üñºÔ∏è Criando colagem para {len(image_group)} imagens")
    print(image_group)

    # Calcular a dura√ß√£o de cada imagem como metade do tempo do verso
    image_clip_duration = verse_duration / len(image_group)
    
    # Criar os clipes das imagens, cada uma com a dura√ß√£o calculada
    image_clips = [ImageClip(img).with_duration(image_clip_duration) for img in image_group]
    
    # Concatenar as imagens em um √∫nico v√≠deo
    return concatenate_videoclips(image_clips, method="compose")

# Fun√ß√£o para sincronizar o v√≠deo com o √°udio
def sync_with_audio(collages, audio_path):
    try:
        # Tentar abrir o arquivo m4a diretamente
        audio = AudioFileClip(audio_path)
    except Exception as e:
        print(f"Erro ao carregar webm: {e}, tentando converter para mp3.")
        # Converter o √°udio se der problema
        audio_path = convert_audio(audio_path)
        audio = AudioFileClip(audio_path)

    video_clips = []
    start_time = 0
    for collage in collages:
        collage = collage.with_start(start_time)
        video_clips.append(collage)
        start_time += collage.duration

    final_video = concatenate_videoclips(video_clips)
    final_video = final_video.with_audio(audio)
    final_video.write_videofile("output_video.mp4", codec="libx264", audio_codec="aac", fps=24)


def convert_audio(input_path):
    output_path = input_path.replace(".webm", ".mp3")
    if not os.path.exists(output_path):
        audio = AudioFileClip(input_path)
        audio.write_audiofile(output_path)
    return output_path